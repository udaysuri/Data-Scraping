{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d6a191a",
   "metadata": {},
   "source": [
    "# Leje Data Scraper\n",
    "#### Made By- Uday S.\n",
    "#### For- Raphael G."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abbd96f",
   "metadata": {},
   "source": [
    "## I. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1a3311c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing drivers\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, WebDriverException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "#importing beautiful soup\n",
    "from bs4 import BeautifulSoup\n",
    "#importing the necessary libraries\n",
    "import pandas as pd, numpy as np\n",
    "#importing json package to read the data\n",
    "import json\n",
    "#importing os module\n",
    "import os\n",
    "from os.path import basename\n",
    "#importing time\n",
    "import time\n",
    "#importing pathlib\n",
    "import pathlib\n",
    "#importing string\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3ef77e",
   "metadata": {},
   "source": [
    "## II. Defining Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0f1e5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining a function to find the position of a substring's nth instance in a string\n",
    "def find_nth(haystack, needle, n):\n",
    "    start = haystack.find(needle)\n",
    "    while start >= 0 and n > 1:\n",
    "        start = haystack.find(needle, start+len(needle))\n",
    "        n -= 1\n",
    "    return start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "888339ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining xpaths\n",
    "Name = '//*[@id=\"auction-title-text\"]/p'\n",
    "Location = '//*[@id=\"info\"]/div[1]/p/a'\n",
    "Date_1 = '//*[@id=\"auction-title-dates\"]/div[1]/div'\n",
    "Val_1 = '//*[@id=\"auction-title-dates\"]/div[1]/div'\n",
    "Date_2 = '//*[@id=\"auction-title-dates\"]/div[2]/div'\n",
    "Val_2 = '//*[@id=\"auction-title-dates\"]/div[2]/div'\n",
    "Visits = '//*[@id=\"auction-views\"]'\n",
    "Commission= '//*[@id=\"winner-bid-value\"]/small'\n",
    "Description= '//*[@id=\"description\"]'\n",
    "Site_Process= '//*[@id=\"description\"]/a'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e51820",
   "metadata": {},
   "source": [
    "## III. Scraping Page Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cf7caaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Selenium to define driver\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "#defining the base url\n",
    "url= \"https://www.leje.com.br/\"\n",
    "#opening the url\n",
    "driver.get(url)\n",
    "#defining variable\n",
    "p_db=\"\"\n",
    "#getting the required element containing page links by class_name\n",
    "p_element = driver.find_elements_by_class_name('auction-card-box ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c20a6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating an empty DataFrame\n",
    "url_df= pd.DataFrame()\n",
    "#Creating an empty \"url\" column with the required rows\n",
    "url_df[\"url\"]= [None] * len(p_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab3815e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using for loop to get the links of all the required pages\n",
    "for i in range(len(p_element)):\n",
    "    #getting the string having the link using get_attribute(), and assigning it to the column\n",
    "    url_df[\"url\"][i]=str(p_element[i].get_attribute(\"onclick\"))\n",
    "    #Cleaning the string to get the exact link for the page using find_nth function defined above\n",
    "    url_df[\"url\"][i]=url+url_df[\"url\"][i][find_nth(url_df[\"url\"][i],\"index\",1):find_nth(url_df[\"url\"][i],\"'\",2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91399836",
   "metadata": {},
   "source": [
    "## IV. Pages' Data Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aada82c",
   "metadata": {},
   "source": [
    "### IV. A) Defining Df Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "834f236f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining empty columns\n",
    "url_df[\"Name\"]=\"\"\n",
    "url_df[\"Location\"]=\"\" \n",
    "url_df[\"1st Square Date\"]=\"\"\n",
    "url_df[\"Evaluation Value 1ª\"]=\"\"\n",
    "url_df[\"2nd Square Date\"]=\"\"\n",
    "url_df[\"Valuation Value 2nd\"]=\"\"\n",
    "url_df[\"Views\"]=\"\"\n",
    "url_df[\"Auctioneer commission\"]=\"\"\n",
    "url_df[\"Useful area\"]=\"\"\n",
    "url_df[\"Total area\"]=\"\"\n",
    "url_df[\"Status\"]=\"\"\n",
    "url_df[\"Garage\"]=\"\"\n",
    "url_df[\"Floor\"]=\"\"\n",
    "url_df[\"Municipal registration\"]=\"\"\n",
    "url_df[\"Registration\"]=\"\"\n",
    "url_df[\"Average condominium value\"]=\"\"\n",
    "url_df[\"Average Annual IPTU value\"]=\"\"\n",
    "url_df[\"Process number\"]=\"\"\n",
    "url_df[\"Site Process\"]=\"\"\n",
    "url_df[\"Payment methods\"]=\"\"\n",
    "url_df[\"Tipo\"]=\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a105c726",
   "metadata": {},
   "source": [
    "### IV. B) Scraping Data Onto Respective Df Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "638af260",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining driver\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "#Using for loop to get the necessary elements and assigning them to the url_df\n",
    "for i in range(len(p_element)):\n",
    "    #opening the url\n",
    "    driver.get(url_df[\"url\"][i])\n",
    "    \n",
    "    #getting the elements using xpath\n",
    "    name_element= driver.find_element_by_xpath(Name)\n",
    "    #using .text on the element to get the required text\n",
    "    url_df[\"Name\"][i]=name_element.text\n",
    "    \n",
    "    #getting the elements using xpath\n",
    "    location_element= driver.find_element_by_xpath(Location)\n",
    "    #using .text on the element to get the required text\n",
    "    url_df[\"Location\"][i]=location_element.text\n",
    "    \n",
    "    #getting the elements using xpath\n",
    "    date_1_element= driver.find_element_by_xpath(Date_1)\n",
    "    #using .text on the element to get the required text and using find_nth/find() to clean the text\n",
    "    url_df[\"1st Square Date\"][i]=date_1_element.text[find_nth(date_1_element.text,\" \",2)+1:date_1_element.text.find(\"\\n\")]\n",
    "    \n",
    "    #getting the elements using xpath\n",
    "    val_1_element= driver.find_element_by_xpath(Val_1)\n",
    "    #using .text on the element to get the required text and using find() to clean the text\n",
    "    url_df[\"Evaluation Value 1ª\"][i]=val_1_element.text[val_1_element.text.find(\"R$\"):]\n",
    "    \n",
    "    #getting the elements using xpath\n",
    "    date_2_element= driver.find_element_by_xpath(Date_2)\n",
    "    #using .text on the element to get the required text and using find_nth/find() to clean the text\n",
    "    url_df[\"2nd Square Date\"][i]=date_2_element.text[find_nth(date_2_element.text,\" \",2)+1:date_2_element.text.find(\"\\n\")]\n",
    "    \n",
    "    #getting the elements using xpath\n",
    "    val_2_element= driver.find_element_by_xpath(Val_2)\n",
    "    #using .text on the element to get the required text and using find() to clean the text\n",
    "    url_df[\"Valuation Value 2nd\"][i]=val_2_element.text[val_2_element.text.find(\"R$\"):]\n",
    "    \n",
    "    #getting the elements using xpath\n",
    "    views_element= driver.find_element_by_xpath('//*[@id=\"auction-views\"]')\n",
    "    #using .text on the element to get the required text\n",
    "    url_df[\"Views\"][i]=views_element.text\n",
    "    \n",
    "    #getting the elements using xpath\n",
    "    commission_element= driver.find_element_by_xpath(Commission)\n",
    "    #using .text on the element to get the required text and using find() to clean the text\n",
    "    url_df[\"Auctioneer commission\"][i]=commission_element.text[commission_element.text.find(\"+\")+1:]\n",
    "    \n",
    "    #getting the elements using xpath\n",
    "    UtilArea_element= driver.find_element_by_xpath(Description)    \n",
    "    #using .text on the element to get the required text\n",
    "    Area_util=UtilArea_element.text\n",
    "    #using if/else statement to clean the data appropriately based on the position of the data in the Descroption Tab\n",
    "    if \"útil\" in Area_util:\n",
    "        Area_util=Area_util[Area_util.find(\"útil\")+6:Area_util.find(\"\\n\")].strip(\" \")\n",
    "        if \"•\" in Area_util:\n",
    "            Area_util=Area_util[:Area_util.find(\"•\")].strip(\" \")\n",
    "    else:\n",
    "        Area_util=\"\"\n",
    "    url_df[\"Useful area\"][i]= Area_util   \n",
    "    \n",
    "    #getting the elements using xpath\n",
    "    TotalArea_element= driver.find_element_by_xpath(Description)\n",
    "    #using .text on the element to get the required text\n",
    "    Area_total=TotalArea_element.text\n",
    "    #using if/else statement to clean the data appropriately based on the position of the data in the Descroption Tab\n",
    "    if \"total\" in Area_total:\n",
    "        Area_total=Area_total[Area_total.find(\"total\")+6:Area_total.find(\"\\n\")].strip(\" \")\n",
    "        if \"•\" in Area_total:\n",
    "            Area_total=Area_total[:Area_total.find(\"•\")].strip(\" \")\n",
    "    else:\n",
    "        Area_total=\"\"\n",
    "    url_df[\"Total area\"][i]= Area_total\n",
    "    \n",
    "    #getting the elements using xpath\n",
    "    Status_element= driver.find_element_by_xpath(Description)\n",
    "    #using .text on the element to get the required text\n",
    "    Status=Status_element.text\n",
    "    #using if/else statement to clean the data appropriately based on the position of the data in the Descroption Tab\n",
    "    if \"Status\" in Status:\n",
    "        Status=Status[Status.find(\"Status\")+7:Status.find(\"\\n\")].strip(\" \")\n",
    "        if \"•\" in Status:\n",
    "            Status= Status[:Status.find(\"•\")].strip(\" \")\n",
    "    else:\n",
    "        Status=\"\"\n",
    "    url_df[\"Status\"][i]=Status\n",
    "    \n",
    "    #getting the elements using xpath\n",
    "    Garage_element= driver.find_element_by_xpath(Description)\n",
    "    #using .text on the element to get the required text\n",
    "    Garage=Garage_element.text\n",
    "    #using if/else statement to clean the data appropriately based on the position of the data in the Descroption Tab\n",
    "    if \"Garage\" in Garage:\n",
    "        Garage=Garage[Garage.find(\"Garage\")+8:Garage.find(\"\\n\")].strip(\" \")\n",
    "        if \"•\" in Garage:\n",
    "            Garage= Garage[:Garage.find(\"•\")]\n",
    "    else:\n",
    "        Garage=\"\"\n",
    "    url_df[\"Garage\"][i]= Garage\n",
    "    \n",
    "    #getting the elements using xpath\n",
    "    Floor_element= driver.find_element_by_xpath(Description)\n",
    "    #using .text on the element to get the required text\n",
    "    Floor=Floor_element.text\n",
    "    #using if/else statement to clean the data appropriately based on the position of the data in the Descroption Tab\n",
    "    if \"Andar\" in Floor:\n",
    "        Floor=Floor[Floor.find(\"Andar\")+7:Floor.find(\"\\n\")].strip(\" \")\n",
    "        if \"•\" in Floor:\n",
    "            Floor= Floor[:Floor.find(\"•\")]\n",
    "    else:\n",
    "        Floor=\"\"\n",
    "    url_df[\"Floor\"][i]=Floor\n",
    "    \n",
    "    #getting the elements using xpath\n",
    "    Municipal_element= driver.find_element_by_xpath(Description)\n",
    "    #using .text on the element to get the required text\n",
    "    Municipal=Municipal_element.text\n",
    "    #using if/else statement to clean the data appropriately based on the position of the data in the Descroption Tab\n",
    "    if \"Cadastro Municipal\" in Municipal:\n",
    "        Municipal=Municipal[Municipal.find(\"Cadastro Municipal\")+19:].strip(\" \")\n",
    "        Municipal=Municipal[:Municipal.find(\".\")]\n",
    "    else:\n",
    "        Municipal=\"\"\n",
    "    url_df[\"Municipal registration\"][i]=Municipal\n",
    "    \n",
    "    #getting the elements using xpath\n",
    "    Registration_element= driver.find_element_by_xpath(Description)\n",
    "    #using .text on the element to get the required text\n",
    "    Registration=Registration_element.text\n",
    "    #using if/else statement to clean the data appropriately based on the position of the data in the Descroption Tab\n",
    "    if \"Matrícula\" in Registration:\n",
    "        Registration=Registration[Registration.find(\"Matrícula\")+14:].strip(\" \")\n",
    "        Registration=Registration[:Registration.find(\"\\n\")]\n",
    "    else:\n",
    "        Registration=\"\"\n",
    "    url_df[\"Registration\"][i]=Registration\n",
    "    \n",
    "    #getting the elements using xpath\n",
    "    condominium_element= driver.find_element_by_xpath(Description)\n",
    "    #using .text on the element to get the required text\n",
    "    condominium=condominium_element.text\n",
    "    #using if/else statement to clean the data appropriately based on the position of the data in the Descroption Tab\n",
    "    if \"Valor médio do Condomínio\" in condominium:\n",
    "        condominium=condominium[condominium.find(\"Valor médio do Condomínio\")+27:].strip(\" \")\n",
    "        condominium=condominium[:condominium.find(\"\\n\")]\n",
    "    else:\n",
    "        condominium=\"\"\n",
    "    url_df[\"Average condominium value\"][i]=condominium\n",
    "    \n",
    "    #getting the elements using xpath\n",
    "    Iptu_element= driver.find_element_by_xpath(Description)\n",
    "    #using .text on the element to get the required text\n",
    "    Iptu=Iptu_element.text\n",
    "    #using if/else statement to clean the data appropriately based on the position of the data in the Descroption Tab\n",
    "    if \"Valor médio do IPTU\" in Iptu:\n",
    "        Iptu=Iptu[Iptu.find(\"Valor médio do IPTU\")+20:].strip(\" \")\n",
    "        Iptu=Iptu[:Iptu.find(\"\\n\")]\n",
    "    else:\n",
    "        Iptu=\"\"\n",
    "    url_df[\"Average Annual IPTU value\"][i]=Iptu\n",
    "    \n",
    "    #getting the elements using xpath\n",
    "    process_element= driver.find_element_by_xpath(Description)\n",
    "    #using .text on the element to get the required text\n",
    "    process=process_element.text\n",
    "    #using if/else statement to clean the data appropriately based on the position of the data in the Descroption Tab\n",
    "    if \"Processo nº:\" in process:\n",
    "        process=process[process.find(\"Processo nº:\")+15:].strip(\" \")\n",
    "        process=process[:process.find(\"\\n\")]\n",
    "    else:\n",
    "        process=\"\"\n",
    "    url_df[\"Process number\"][i]=process\n",
    "    \n",
    "    #getting the elements using xpath\n",
    "    site_element= driver.find_element_by_xpath(Site_Process)\n",
    "    #using .get_attribute() on the element to get the required text \n",
    "    site=site_element.get_attribute(\"href\")\n",
    "    url_df[\"Site Process\"][i]=site\n",
    "    \n",
    "    #getting the elements using xpath\n",
    "    Payment_element= driver.find_element_by_xpath(Description)\n",
    "    #using .text on the element to get the required text\n",
    "    Payment=Payment_element.text\n",
    "    #using if/else statement to clean the data appropriately based on the position of the data in the Descroption Tab\n",
    "    if \"Formas de Pagamento\" in Payment:\n",
    "        Payment=Payment[Payment.find(\"Formas de Pagamento\")+20:].strip(\" \")\n",
    "        Payment=Payment[:Payment.find(\"\\n\")]\n",
    "    else:\n",
    "        Payment=\"\"\n",
    "    url_df[\"Payment methods\"][i]=Payment\n",
    "    \n",
    "    #getting the elements using xpath\n",
    "    Tipo_element= driver.find_element_by_xpath(Description)\n",
    "    #using .text on the element to get the required text\n",
    "    Tipo=Tipo_element.text\n",
    "    #using if/else statement to clean the data appropriately based on the position of the data in the Descroption Tab\n",
    "    if \"Tipo:\" in Tipo:\n",
    "        Tipo=Tipo[Tipo.find(\"Tipo:\")+6:Tipo.find(\"\\n\")].strip(\" \")\n",
    "        if \"•\" in Tipo:\n",
    "            Tipo=Tipo[:Tipo.find(\"•\")].strip(\" \")\n",
    "    else:\n",
    "        Tipo=\"\"\n",
    "    url_df[\"Tipo\"][i]=Tipo\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e5b986",
   "metadata": {},
   "source": [
    "### VI. Downloading The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbecbebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downloading the url_df to an excel file\n",
    "url_df.to_excel(\"Leje.xlsx\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
