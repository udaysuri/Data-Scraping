{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d6a191a",
   "metadata": {},
   "source": [
    "# Megaleiloes PDF/Image Scraper\n",
    "#### Made By- Uday S.\n",
    "#### For- Raphael G."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abbd96f",
   "metadata": {},
   "source": [
    "## I. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "740e4651",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing drivers\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, WebDriverException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "#importing beautiful soup\n",
    "from bs4 import BeautifulSoup\n",
    "# Import requests\n",
    "import requests\n",
    "  \n",
    "#importing the necessary libraries\n",
    "import pandas as pd, numpy as np\n",
    "#importing json package to read the data\n",
    "import json\n",
    "\n",
    "#importing os module\n",
    "import os\n",
    "from os.path import basename\n",
    "#importing time\n",
    "import time\n",
    "#importing pathlib\n",
    "import pathlib\n",
    "#importing string\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ca334c",
   "metadata": {},
   "source": [
    "## II. Defining Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fd8ab8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining a function to find the position of a substring's nth instance in a string\n",
    "def find_nth(haystack, needle, n):\n",
    "    start = haystack.find(needle)\n",
    "    while start >= 0 and n > 1:\n",
    "        start = haystack.find(needle, start+len(needle))\n",
    "        n -= 1\n",
    "    return start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e51820",
   "metadata": {},
   "source": [
    "## III. Scraping Page Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59369dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Selenium to define driver\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "url= \"https://www.megaleiloes.com.br/imoveis\"\n",
    "driver.get(url)\n",
    "p_db=\"\"\n",
    "for i in range(13):\n",
    "    time.sleep(5)\n",
    "    p_element = driver.find_element_by_xpath('//*[@id=\"w0\"]/div[1]')\n",
    "    p_db= p_db + \" \" +p_element.get_attribute('innerHTML')# Getting attributes of an element\n",
    "    try:\n",
    "        click_element = driver.find_element_by_xpath('//*[@id=\"w0\"]/div[2]/ul/li[11]/a')\n",
    "        click_element.click()\n",
    "    except:\n",
    "        pass\n",
    "url_df= pd.DataFrame()\n",
    "url_df[\"url\"]= [None] * 584\n",
    "\n",
    "for i in range(584):\n",
    "    try:\n",
    "        url_df[\"url\"][i]= p_db[find_nth(p_db,'class=\"card-title\" href=\"',i+1)+25:find_nth(p_db,'\" data-pjax=\"0\">',(3*i)+1)]\n",
    "        a=i\n",
    "    except:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b60713b",
   "metadata": {},
   "source": [
    "## IV. Defining Columns And Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e86172f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the Name column\n",
    "url_df[\"Name\"]=\"\"\n",
    "#Using for loop to iterate through the rows to fill the Name column with the appropriate name to use as file names\n",
    "for i in range(len(url_df)):\n",
    "    url_df[\"Name\"][i]= url_df[\"url\"][i][find_nth(url_df[\"url\"][i],\"/\",7)+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45a0f2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining Parent Directory\n",
    "parent_dir = os.getcwd()\n",
    "# Directory\n",
    "directory = \"Megaleiloes\"\n",
    "# Directory paths\n",
    "path = os.path.join(parent_dir, directory)\n",
    "# Create the directory\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b56522b",
   "metadata": {},
   "source": [
    "## V. Downloading PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b59bbdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(len(url_df)):\n",
    "    # URL from which pdfs to be downloaded\n",
    "    url = url_df[\"url\"][n]\n",
    "\n",
    "    # Requests URL and get response object\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Parse text obtained\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find all hyperlinks present on webpage\n",
    "    links = soup.find_all('a')\n",
    "\n",
    "    i = 0\n",
    "    \n",
    "    \n",
    "    d1= url_df[\"Name\"][n]\n",
    "    # Directory paths\n",
    "    path1= os.path.join(path, d1)\n",
    "\n",
    "    # Create the directory\n",
    "    if not os.path.exists(path1):\n",
    "        os.mkdir(path1)\n",
    "    else:\n",
    "        pass\n",
    "    # From all links check for pdf link and\n",
    "    # if present download file\n",
    "    for link in links:\n",
    "        if ('.pdf' in link.get('href', [])):\n",
    "            i += 1\n",
    "            print(\"Downloading file: \", n,\": \",i)\n",
    "\n",
    "            # Get response object for link\n",
    "            response = requests.get(link.get('href'))\n",
    "            if i==1:\n",
    "                j=\"Edital\"\n",
    "            elif i==2:\n",
    "                j=\"Laudo de avaliação\"\n",
    "            elif i==3:\n",
    "                j=\"Matrícula\"\n",
    "            # Write content in pdf file\n",
    "            pdf = open(directory+\"/\"+d1+\"/\"+j+\".pdf\", 'wb')\n",
    "            pdf.write(response.content)\n",
    "            pdf.close()\n",
    "            print(\"File \", n,\": \",i, \" downloaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042768bb",
   "metadata": {},
   "source": [
    "## VI. Downloading Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30f7302f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(len(url_df)):\n",
    "    # URL from which jpgs to be downloaded\n",
    "    url = url_df[\"url\"][n]\n",
    "\n",
    "    # Requests URL and get response object\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Parse text obtained\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find all hyperlinks present on webpage\n",
    "    links = soup.find_all('img')\n",
    "\n",
    "    i = 0\n",
    "\n",
    "\n",
    "    d1= url_df[\"Name\"][n]\n",
    "    # Directory paths\n",
    "    path1= os.path.join(path, d1)\n",
    "\n",
    "    # Create the directory\n",
    "    if not os.path.exists(path1):\n",
    "        os.mkdir(path1)\n",
    "    else:\n",
    "        pass\n",
    "    # From all links check for jpg link and\n",
    "    # if present download file\n",
    "    for link in links:\n",
    "        if \".jpg\" in str(link):\n",
    "            i += 1\n",
    "            \n",
    "            print(\"Downloading file: \", n,\": \",i)\n",
    "            # Get response object for link\n",
    "            response = requests.get(link.get(\"src\"))\n",
    "            # Write content in jpg file\n",
    "            jpg = open(directory+\"/\"+d1+\"/\"+str(i)+\".jpg\", 'wb')\n",
    "            jpg.write(response.content)\n",
    "            jpg.close()\n",
    "            print(\"File \", n,\": \",i, \" downloaded\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
